{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaasb\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\algorithms.py:522: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  common = np.find_common_type([values.dtype, comps_array.dtype], [])\n"
     ]
    }
   ],
   "source": [
    "from Classes.DataPreparator import DataPreparator\n",
    "\n",
    "buildings_path = \"Sample/Data/Buildings lists/Buildings Campus Terrassa.csv\"\n",
    "cadastre_path = \"Sample/Data/Cadastre files\"\n",
    "LiDAR_path = \"Sample/Data/LiDAR files\"\n",
    "output_path = \"Sample/Results/Data Preparation\"\n",
    "\n",
    "dataprep = DataPreparator(buildings_path, cadastre_path, LiDAR_path, output_path)\n",
    "dataprep.prepare_buildings(source=4326, target=25831)\n",
    "dataprep.prepare_cadastre(source=4326, target=25831)\n",
    "dataprep.prepare_LiDAR(las2txtPath=\"C:/LAStools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Solar energy estimation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TR4\n",
      "Group: 0\n",
      "\t Found plane. Percentatge remaining: 0.25\n",
      "\t Run out of iterations\n",
      "Group: 1\n",
      "\t Found plane. Percentatge remaining: 0.6666666666666666\n",
      "\t Found plane. Percentatge remaining: 0.08333333333333333\n",
      "\t Run out of iterations\n",
      "Group: 2\n",
      "\t Found plane. Percentatge remaining: 0.9243697478991597\n",
      "\t Found plane. Percentatge remaining: 0.36134453781512604\n",
      "\t Found plane. Percentatge remaining: 0.2605042016806723\n",
      "\t Found plane. Percentatge remaining: 0.20168067226890757\n",
      "\t Found plane. Percentatge remaining: 0.1092436974789916\n",
      "\t Run out of iterations\n",
      "Group: 3\n",
      "\t Found plane. Percentatge remaining: 0.8246097337006428\n",
      "\t Found plane. Percentatge remaining: 0.7502295684113865\n",
      "\t Found plane. Percentatge remaining: 0.5941230486685032\n",
      "\t Found plane. Percentatge remaining: 0.49403122130394855\n",
      "\t Found plane. Percentatge remaining: 0.40771349862258954\n",
      "\t Found plane. Percentatge remaining: 0.31955922865013775\n",
      "\t Found plane. Percentatge remaining: 0.2396694214876033\n",
      "\t Found plane. Percentatge remaining: 0.16988062442607896\n",
      "\t Run out of iterations\n",
      "\t Plane identification done\n",
      "1 5\n",
      "6 7\n",
      "6 8\n",
      "\t Plane processing done\n",
      "TR45\n",
      "Group: 0\n",
      "\t Found plane. Percentatge remaining: 0.9206349206349206\n",
      "\t Found plane. Percentatge remaining: 0.8253968253968254\n",
      "\t Found plane. Percentatge remaining: 0.49206349206349204\n",
      "\t Found plane. Percentatge remaining: 0.4126984126984127\n",
      "\t Found plane. Percentatge remaining: 0.31746031746031744\n",
      "\t Found plane. Percentatge remaining: 0.2222222222222222\n",
      "\t Found plane. Percentatge remaining: 0.15873015873015872\n",
      "\t Found plane. Percentatge remaining: 0.09523809523809523\n",
      "\t Run out of iterations\n",
      "Group: 1\n",
      "\t Found plane. Percentatge remaining: 0.6666666666666666\n",
      "\t Found plane. Percentatge remaining: 0.08333333333333333\n",
      "\t Run out of iterations\n",
      "Group: 2\n",
      "\t Found plane. Percentatge remaining: 0.6666666666666666\n",
      "\t Found plane. Percentatge remaining: 0.0\n",
      "\t Run out of iterations\n",
      "Group: 3\n",
      "\t Found plane. Percentatge remaining: 0.28205128205128205\n",
      "\t Found plane. Percentatge remaining: 0.1282051282051282\n",
      "\t Found plane. Percentatge remaining: 0.02564102564102564\n",
      "\t Run out of iterations\n",
      "Group: 4\n",
      "\t Found plane. Percentatge remaining: 0.643859649122807\n",
      "\t Found plane. Percentatge remaining: 0.4105263157894737\n",
      "\t Found plane. Percentatge remaining: 0.35789473684210527\n",
      "\t Found plane. Percentatge remaining: 0.3017543859649123\n",
      "\t Found plane. Percentatge remaining: 0.24912280701754386\n",
      "\t Found plane. Percentatge remaining: 0.18947368421052632\n",
      "\t Run out of iterations\n",
      "\t Plane identification done\n",
      "\t Plane processing done\n",
      "TR5\n",
      "Group: 0\n",
      "\t Found plane. Percentatge remaining: 0.5967741935483871\n",
      "\t Found plane. Percentatge remaining: 0.5\n",
      "\t Found plane. Percentatge remaining: 0.43548387096774194\n",
      "\t Found plane. Percentatge remaining: 0.3225806451612903\n",
      "\t Found plane. Percentatge remaining: 0.24193548387096775\n",
      "\t Found plane. Percentatge remaining: 0.1774193548387097\n",
      "\t Run out of iterations\n",
      "Group: 1\n",
      "\t Found plane. Percentatge remaining: 0.8\n",
      "\t Found plane. Percentatge remaining: 0.5333333333333333\n",
      "\t Found plane. Percentatge remaining: 0.3333333333333333\n",
      "\t Found plane. Percentatge remaining: 0.13333333333333333\n",
      "\t Run out of iterations\n",
      "Group: 2\n",
      "\t Found plane. Percentatge remaining: 0.6947115384615384\n",
      "\t Found plane. Percentatge remaining: 0.5240384615384616\n",
      "\t Found plane. Percentatge remaining: 0.3798076923076923\n",
      "\t Found plane. Percentatge remaining: 0.23076923076923078\n",
      "\t Found plane. Percentatge remaining: 0.17307692307692307\n"
     ]
    }
   ],
   "source": [
    "from Classes.SolarEstimator import SolarEstimator\n",
    "import pandas as pd\n",
    "\n",
    "srcCadaster=4326\n",
    "srcLiDAR=25831\n",
    "\n",
    "LiDAR_info_path = \"Sample/Results/Data Preparation/LiDAR/LiDAR_Limits.csv\"\n",
    "cadastre_info_path = \"Sample/Results/Data Preparation/Cadastre/Cadastre_Limits.csv\"\n",
    "cadastre_path = \"Sample/Data/Cadastre files\"\n",
    "LiDAR_path = \"Sample/Data/LiDAR files\"\n",
    "tmyfile = \"Sample/Data/TMY_Terrassa-2018.csv\"\n",
    "buildings_info_path = \"Sample/Results/Data Preparation/Buildings/Buildings_filtered.csv\"\n",
    "\n",
    "output_path = \"Sample/Results\"\n",
    "\n",
    "buildings = pd.read_csv(buildings_info_path) \n",
    "buildingsID = buildings.identifier.values\n",
    "\n",
    "for buildingID in buildingsID[3:6]:\n",
    "    building = buildings[buildings.identifier == buildingID].reset_index(drop=True)\n",
    "    print(buildingID)\n",
    "    \n",
    "    solarestimator = SolarEstimator(building, output_path, srcLiDAR=srcLiDAR, square_side=500, temp_path=\"Sample/Results/_Temp\")\n",
    "    solarestimator.loadData(LiDAR_info_path, cadastre_info_path, LiDAR_path, cadastre_path)\n",
    "    # solarestimator.segmentLiDAR(square_side=500)   \n",
    "    # solarestimator.createNeighborhood(LAStoolsPath=\"C:/LAStools\", export3D=True) \n",
    "\n",
    "    solarestimator.identifyPlanes(minGlobalPercentage=0.05, minPartialPercentage=0.5, heightThreshold=0.5, distanceThreshold=0.2, ransacIterations=20, densityMultiplier=0.125, stoppingPercentage=0.2)\n",
    "    print(\"\\t Plane identification done\")\n",
    "\n",
    "    solarestimator.processPlanes(srcCadaster=srcCadaster, generateFigures=True, slidingHole=0.75, minHoleSide = 2.5)\n",
    "    print(\"\\t Plane processing done\")\n",
    "\n",
    "    # solarestimator.computeShading(generateFigures=False, Nsamples=25, div=2, bufferSize=1, shadeInside=True)\n",
    "    # print(\"\\t Shading done\")\n",
    "    # solarestimator.simulatePySAM(tmyfile, generateFigures=False)\n",
    "    # solarestimator.plotEnergyMap()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eP-EAZK-050\n",
      "Group: 0\n",
      "\t Found plane. Percentatge remaining: 0.5714285714285714\n",
      "\t Found plane. Percentatge remaining: 0.0\n",
      "\t Run out of iterations\n",
      "Group: 1\n",
      "\t Found plane. Percentatge remaining: 0.6153846153846154\n",
      "\t Found plane. Percentatge remaining: 0.0\n",
      "\t Run out of iterations\n",
      "Group: 2\n",
      "\t Found plane. Percentatge remaining: 0.8656126482213439\n",
      "\t Found plane. Percentatge remaining: 0.7799736495388669\n",
      "\t Found plane. Percentatge remaining: 0.6798418972332015\n",
      "\t Found plane. Percentatge remaining: 0.6258234519104084\n",
      "\t Found plane. Percentatge remaining: 0.5546772068511199\n",
      "\t Found plane. Percentatge remaining: 0.45849802371541504\n",
      "\t Found plane. Percentatge remaining: 0.40843214756258234\n",
      "\t Found plane. Percentatge remaining: 0.3359683794466403\n",
      "\t Found plane. Percentatge remaining: 0.2437417654808959\n",
      "\t Found plane. Percentatge remaining: 0.19235836627140976\n",
      "\t Found plane. Percentatge remaining: 0.11989459815546773\n",
      "\t Run out of iterations\n",
      "\t Plane identification done\n",
      "3 7\n",
      "3 8\n",
      "4 7\n",
      "\t Plane processing done\n",
      "eP-EAZK-076\n",
      "Group: 0\n",
      "\t Found plane. Percentatge remaining: 0.7336448598130841\n",
      "\t Found plane. Percentatge remaining: 0.09968847352024922\n",
      "\t Found plane. Percentatge remaining: 0.020249221183800622\n",
      "\t Found plane. Percentatge remaining: 0.004672897196261682\n",
      "\t Run out of iterations\n",
      "Group: 1\n",
      "\t Found plane. Percentatge remaining: 0.6538461538461539\n",
      "\t Found plane. Percentatge remaining: 0.007692307692307693\n",
      "\t Run out of iterations\n",
      "\t Plane identification done\n",
      "\t Plane processing done\n",
      "eP-EAZK-085\n",
      "Group: 0\n",
      "\t Found plane. Percentatge remaining: 0.45987654320987653\n",
      "\t Found plane. Percentatge remaining: 0.2138447971781305\n",
      "\t Found plane. Percentatge remaining: 0.1402116402116402\n",
      "\t Run out of iterations\n",
      "Group: 1\n",
      "\t Found plane. Percentatge remaining: 0.6216216216216216\n",
      "\t Found plane. Percentatge remaining: 0.12162162162162163\n",
      "\t Found plane. Percentatge remaining: 0.02702702702702703\n",
      "\t Run out of iterations\n",
      "\t Plane identification done\n",
      "\t Plane processing done\n",
      "eP-EAZK-162\n",
      "Group: 0\n",
      "\t Found plane. Percentatge remaining: 0.75\n",
      "\t Found plane. Percentatge remaining: 0.2\n",
      "\t Found plane. Percentatge remaining: 0.025\n",
      "\t Run out of iterations\n",
      "Group: 1\n",
      "\t Found plane. Percentatge remaining: 0.8306010928961749\n",
      "\t Found plane. Percentatge remaining: 0.4936247723132969\n",
      "\t Found plane. Percentatge remaining: 0.43897996357012753\n",
      "\t Found plane. Percentatge remaining: 0.29326047358834245\n",
      "\t Found plane. Percentatge remaining: 0.23679417122040072\n",
      "\t Found plane. Percentatge remaining: 0.1657559198542805\n",
      "\t Run out of iterations\n",
      "\t Plane identification done\n",
      "0 1\n",
      "0 2\n",
      "1 3\n",
      "2 3\n",
      "\t Plane processing done\n",
      "eP-EAZK-163\n",
      "Group: 0\n",
      "\t Found plane. Percentatge remaining: 0.3435897435897436\n",
      "\t Found plane. Percentatge remaining: 0.05384615384615385\n",
      "\t Found plane. Percentatge remaining: 0.015384615384615385\n",
      "\t Found plane. Percentatge remaining: 0.002564102564102564\n",
      "\t Run out of iterations\n",
      "Group: 1\n",
      "\t Found plane. Percentatge remaining: 0.0\n",
      "\t Run out of iterations\n",
      "Group: 2\n",
      "\t Found plane. Percentatge remaining: 0.6982248520710059\n",
      "\t Found plane. Percentatge remaining: 0.045364891518737675\n",
      "\t Run out of iterations\n",
      "Group: 3\n",
      "\t Found plane. Percentatge remaining: 0.5\n",
      "\t Run out of iterations\n",
      "Group: 4\n",
      "\t Found plane. Percentatge remaining: 0.8\n",
      "\t Found plane. Percentatge remaining: 0.2375\n",
      "\t Found plane. Percentatge remaining: 0.125\n",
      "\t Found plane. Percentatge remaining: 0.0375\n",
      "\t Run out of iterations\n",
      "Group: 5\n",
      "\t Found plane. Percentatge remaining: 0.8568507157464212\n",
      "\t Found plane. Percentatge remaining: 0.4918200408997955\n",
      "\t Found plane. Percentatge remaining: 0.29243353783231085\n",
      "\t Found plane. Percentatge remaining: 0.16768916155419222\n",
      "\t Found plane. Percentatge remaining: 0.11247443762781185\n",
      "\t Run out of iterations\n",
      "\t Plane identification done\n",
      "0 1\n",
      "0 2\n",
      "1 2\n",
      "4 6\n",
      "6 7\n",
      "\t Plane processing done\n",
      "eP-EAZK-165\n",
      "Group: 0\n",
      "\t Found plane. Percentatge remaining: 0.5534290271132376\n",
      "\t Found plane. Percentatge remaining: 0.291866028708134\n",
      "\t Found plane. Percentatge remaining: 0.16267942583732056\n",
      "\t Run out of iterations\n",
      "\t Plane identification done\n",
      "\t Plane processing done\n"
     ]
    }
   ],
   "source": [
    "from Classes.SolarEstimator import SolarEstimator\n",
    "import pandas as pd\n",
    "\n",
    "cadastre=3035\n",
    "lidar=5514\n",
    "\n",
    "LiDAR_info_path = \"Sample/Results/Data Preparation/LiDAR/LiDAR_Limits.csv\"\n",
    "cadastre_info_path = \"Sample/Results/Data Preparation/Cadastre/Cadastre_Limits.csv\"\n",
    "cadastre_path = \"Sample/Data/Cadastre files\"\n",
    "LiDAR_path = \"Sample/Data/LiDAR files\"\n",
    "tmyfile = \"Sample/Data/TMY_Terrassa-2018.csv\"\n",
    "buildings_info_path = r\"C:\\Users\\jaasb\\INVESTIGO\\BEE Group\\eplanet shared\\Programa Final\\Results\\Data Preparation\\Buildings\\Buildings_filtered.csv\"\n",
    "\n",
    "output_path = \"Sample/Results\"\n",
    "\n",
    "buildings = pd.read_csv(buildings_info_path) \n",
    "\n",
    "buildingsID = ['eP-EAZK-050', 'eP-EAZK-076', 'eP-EAZK-085', 'eP-EAZK-162', 'eP-EAZK-163', 'eP-EAZK-165']\n",
    "\n",
    "for buildingID in buildingsID:\n",
    "    building = buildings[buildings.identifier == buildingID].reset_index(drop=True)\n",
    "    print(buildingID)\n",
    "    \n",
    "    solarestimator = SolarEstimator(building, output_path, srcLiDAR=lidar, square_side=500, temp_path=\"Sample/Results/_Temp\")\n",
    "    solarestimator.loadData(LiDAR_info_path, cadastre_info_path, LiDAR_path, cadastre_path)\n",
    "    # solarestimator.segmentLiDAR(square_side=500)   \n",
    "    # solarestimator.createNeighborhood(LAStoolsPath=\"C:/LAStools\", export3D=True) \n",
    "\n",
    "    solarestimator.identifyPlanes(minGlobalPercentage=0.05, minPartialPercentage=0.5, heightThreshold=0.5, distanceThreshold=0.2, ransacIterations=20, densityMultiplier=0.125, stoppingPercentage=0.2)\n",
    "    print(\"\\t Plane identification done\")\n",
    "\n",
    "    solarestimator.processPlanes(srcCadaster=cadastre, generateFigures=True, slidingHole=0.75, minHoleSide = 2.5)\n",
    "    print(\"\\t Plane processing done\")\n",
    "\n",
    "    # solarestimator.computeShading(generateFigures=False, Nsamples=25, div=2, bufferSize=1, shadeInside=True)\n",
    "    # print(\"\\t Shading done\")\n",
    "    # solarestimator.simulatePySAM(tmyfile, generateFigures=False)\n",
    "    # solarestimator.plotEnergyMap()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it was thought for all LiDAR data to be in one directory, data has been merged before loading the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Results/Data Preparation/Buildings/Buildings_filtered.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      7\u001b[0m buildings_info_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResults/Data Preparation/Buildings/Buildings_filtered.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 8\u001b[0m buildings \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuildings_info_path\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# This is for peace of mind and ease of debugging\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Results/Data Preparation/Buildings/Buildings_filtered.csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from Functions.general_functions import create_output_folder\n",
    "# Get a list of buildings and select a building for testing\n",
    "\n",
    "import pandas as pd\n",
    "buildings_info_path = \"Results/Data Preparation/Buildings/Buildings_filtered.csv\"\n",
    "buildings = pd.read_csv(buildings_info_path) \n",
    "\n",
    "# This is for peace of mind and ease of debugging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from Classes.SolarEstimator import SolarEstimator\n",
    "\n",
    "LiDAR_info_path = \"Results/Data Preparation/LiDAR/LiDAR_Limits.csv\"\n",
    "cadastre_info_path = \"Results/Data Preparation/Cadastre/Cadastre_Limits.csv\"\n",
    "cadastre_path = \"Data/v0_1-CZE\"\n",
    "LiDAR_path = \"Data/DVDs\"\n",
    "tmyfile = \"Data/Zlin_TMY/Zlin_TMY.csv\"\n",
    "\n",
    "output_path = \"Results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildingsID = ['eP-EAZK-322']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for buildingID in buildingsID:\n",
    "    building = buildings[buildings.identifier == buildingID].reset_index(drop=True)\n",
    "    \n",
    "    solarestimator = SolarEstimator(building, output_path)\n",
    "    \n",
    "    solarestimator.loadData(LiDAR_info_path, cadastre_info_path, LiDAR_path, cadastre_path)\n",
    "\n",
    "    solarestimator.segmentLiDAR(stl_side=500, partitioned=True)\n",
    "    solarestimator.generateSTL() \n",
    "\n",
    "    solarestimator.identifyPlanes(generateFigures=True, minGlobalPercentage=0.4, minPartialPercentage=0.5, heightThreshold=0.5, distanceThreshold=0.1, \n",
    "                                  ransacIterations=20, stoppingPercentage=0.05, pdfExponent=2, deleteFirst=True)\n",
    "    print(\"\\t Plane identification done\")\n",
    "\n",
    "    solarestimator.processPlanes(generateFigures=True, slidingHole=0.5, minHoleSide = 2.5)\n",
    "    print(\"\\t Plane processing done\")\n",
    "\n",
    "    solarestimator.computeShading(generateFigures=False, Nsamples=25, div=2, bufferSize=1, shadeInside=True)\n",
    "    print(\"\\t Shading done\")\n",
    "    solarestimator.simulatePySAM(tmyfile, multipleTilts=False)\n",
    "    \n",
    "    del solarestimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Extra code**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *File management*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "directory_path = \"Results/Data Preparation/LiDAR/By DVD\"\n",
    "\n",
    "# Get a list of all CSV files in the specified directory\n",
    "csv_files = [file for file in os.listdir(directory_path) if file.endswith('.csv')]\n",
    "\n",
    "# Check if there are any CSV files in the directory\n",
    "if not csv_files:\n",
    "    print(\"No CSV files found in the specified directory.\")\n",
    "\n",
    "# Initialize an empty dataframe to store the merged data\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# Loop through each CSV file and merge it into the main dataframe\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(directory_path, csv_file)\n",
    "    # Read the CSV file into a dataframe\n",
    "    df = pd.read_csv(file_path)\n",
    "    # Merge the dataframe into the main dataframe\n",
    "    merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "\n",
    "merged_df\n",
    "merged_df.to_csv(\"Results/Data Preparation/LiDAR/LiDAR_Limits.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "source_directory = \"Data/DVDs/All DVD\"\n",
    "destination_directory = \"Data/DVDs\"\n",
    "\n",
    "# Ensure the destination directory exists; create it if not\n",
    "if not os.path.exists(destination_directory):\n",
    "    os.makedirs(destination_directory)\n",
    "    print(f\"Created destination directory: '{destination_directory}'\")\n",
    "\n",
    "# Get a list of all files in the source directory\n",
    "files = [f for f in os.listdir(source_directory) if os.path.isfile(os.path.join(source_directory, f))]\n",
    "\n",
    "# Move each file to the destination directory\n",
    "for file in files:\n",
    "    source_path = os.path.join(source_directory, file)\n",
    "    destination_path = os.path.join(destination_directory, file)\n",
    "    shutil.move(source_path, destination_path)\n",
    "    print(f\"Moved: {source_path} -> {destination_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *If plane identification is split, this helps merging*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Functions.general_functions import create_output_folder\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "buildingJoin = \"eP-EAZK-322\"\n",
    "numberFolders = 8\n",
    "folderPath = output_path + \"/\" + buildingJoin\n",
    "\n",
    "mergedPath = folderPath + \"/\" + \"04 - Plane Processing\"\n",
    "create_output_folder(mergedPath)\n",
    "create_output_folder(mergedPath + \"/01 - Results\")\n",
    "\n",
    "# Plane info\n",
    "planeList = pd.read_csv(mergedPath +\" - còpia/01 - Results/PlaneList_\" + buildingJoin + \".csv\")\n",
    "\n",
    "for i in range(numberFolders-1):\n",
    "    partialPlaneList = pd.read_csv(mergedPath +\" - còpia (\" + str(i+2) + \")/01 - Results/PlaneList_\" + buildingJoin + \".csv\")\n",
    "    planeList = pd.concat([planeList, partialPlaneList])\n",
    "\n",
    "planeList.to_csv(mergedPath + \"/01 - Results/PlaneList_\" + buildingJoin + \".csv\", index=False)\n",
    "\n",
    "# Planes points\n",
    "dir_path = mergedPath +\" - còpia/01 - Results/\" \n",
    "n_planes = len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))])\n",
    "currentN = 0\n",
    "\n",
    "for i in range(n_planes-1):\n",
    "    src = dir_path + \"/\" + buildingJoin + \"_\" + str(i) + \".csv\"\n",
    "    dst = mergedPath + \"/01 - Results/\" + buildingJoin + \"_\" + str(currentN) + \".csv\"\n",
    "    currentN = currentN + 1\n",
    "    shutil.copy(src, dst)\n",
    "\n",
    "for i in range(numberFolders-1):\n",
    "    dir_path = mergedPath + \" - còpia (\" + str(i+2) + \")/01 - Results/\" \n",
    "    n_planes = len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))])\n",
    "    for i in range(n_planes-1):\n",
    "        src = dir_path + \"/\" + buildingJoin + \"_\" + str(i) + \".csv\"\n",
    "        dst = mergedPath + \"/01 - Results/\" + buildingJoin + \"_\" + str(currentN) + \".csv\"\n",
    "        currentN = currentN + 1\n",
    "        shutil.copy(src, dst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-qgis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
